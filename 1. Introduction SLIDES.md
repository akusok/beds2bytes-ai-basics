---
marp: true
title: AI in Healthcare – Introduction
paginate: true
theme: default
_class: lead
---

# AI in Healthcare  
## Introduction to AI

<!-- presenter: Set hook: “Fast answers, zero real memory. How?” -->

---

## Classic ML = Numbers

- Everything → numbers
- Iris example: measured features → math → class

<!-- presenter: Emphasize: old ML fine for structured, not language. -->

---

## Why Text Was Hard

Naive idea: word list → IDs

apple = 1 • aunt = 2 • airplane = 3

Problem: math lies (airplane - apple ≠ aunt)

<!-- presenter: Say out loud the absurd equations to make it memorable. -->

---

## Breakthrough Idea

Not numbers ON words…  
Numbers BETWEEN words (relationships / co‑occurrence)

(red, apple) >> (red, aunt)

<!-- presenter: Stress: relationships form a network. -->

---

## Attention (Core Trick)

Model asks:  
“For THIS token, which earlier tokens matter most?”

<!-- presenter: Gesture scanning back in a sentence. -->

---

## Multi‑Head Attention

Different “heads” = different relation lenses  
(color) (syntax) (topic) (entity) …

<!-- presenter: Point out many heads (e.g. 32–100+) each specializing emergently. -->

---

## Next Token Loop

1. Read prior tokens  
2. Attention weighting  
3. Probabilities over vocab  
4. Pick next token  
5. Repeat

<!-- presenter: Clarify: No thinking—iterative pattern continuation. -->

---

## No True Memory

Learns from training  
Remembers nothing about YOU between calls

“Memory” = rereading recent text

<!-- presenter: Contrast with human episodic memory. -->

---

## Context Window

Fixed token budget (e.g. 4K … 200K)  
Oldest tokens fall out when full

<!-- presenter: Use whiteboard motion: sliding window forward. -->

---

## Consequence: Forgetting

Overflow → instant amnesia  
Can forget mid‑reply if long

<!-- presenter: Explain pricing cost scales with context length. -->

---

## Context Engineering

Stuff window with:  
- User instructions  
- Key facts / docs  
- Summaries of earlier parts

<!-- presenter: Say “We pack a lunch before sending the model to work.” -->

---

## RAG (Retrieval)

Ask a text index → inject only top relevant chunks

More precise than dumping huge docs

<!-- presenter: Note retrieval can miss if phrasing differs. -->

---

## “Long‑Term Memory”

External file(s) + (optional) RAG  
Re‑attach next session → pseudo recall

<!-- presenter: Clarify it’s tooling, not model neurons changing. -->

---

## Tools (Functions)

Model decides: “Call calculator? Run search?”  
You register functions → model uses them

<!-- presenter: Example: dosage calc, date parser. -->

---

## MCP (Model Context Protocol)

Standard “plug” to expose tools/resources  
Like USB for models

Powerful + security hygiene required

<!-- presenter: Warn: treat unknown tool sources like unknown USB sticks. -->

---

## Guardrails

Filter / check layer:  
- Appropriateness  
- Factual sanity  
- Policy / compliance

Examples: “We forgive you” / “Do it tomorrow”

<!-- presenter: Mention multi‑LLM (generator + judge) or code rules. -->

---

## Recap

Tokens + Attention ≠ understanding  
Context window = short‑term buffer  
Memory ≈ engineered context + retrieval  
Tools & MCP extend capability  
Guardrails keep outputs usable & safe

<!-- presenter: Tease next: full lifecycle of a user message. -->

---
## Next Up

AI Lifecycle: “What happens when I send a message?”

<!-- presenter: Call to action: Watch next module. -->