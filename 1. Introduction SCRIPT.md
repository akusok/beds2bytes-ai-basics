# Performance Script — Introduction (compact markdown)

## Anatomy

1. Segment header with target time (e.g., Segment 2: Problem – 0:30–1:30).
2. Spoken column:
    * VERBATIM lines (you memorize or closely follow) for hook, promise, transitions, definitions.
    * Bullet prompts for explanations (each bullet ≈ 6–8 seconds).
3. Visual/action column:
    * Slide number or “A-roll face”, “Slide 3 appear tokens”, “Overlay label: Attention”.
    * Editing cues like (CUT), (ZOOM 110%), (PAUSE 0.5s).
4. Optional emphasis markers: CAPS, [beat], (gesture).

## Creation workflow (fast)

1. List segments with time budgets.
2. For each: write the one sentence outcome (viewer should now understand X).
3. Draft only the verbatim lines first.
4. Add bullet prompts under each to cover supporting points.
5. Add visual cues last (ensures slides serve message, not vice versa).
6. Read it aloud + stopwatch; trim until total fits.

## How detailed?

* Average 1 bullet per 6–8 seconds.
* 10‑minute video → ~75–90 bullets (including verbatim lines).
* If you can’t remember a bullet naturally, convert it to a short verbatim sentence.

## Delivery trick

* Print or keep on side monitor.
* Glance → deliver 1–2 bullets → look back. Natural eye movement beats reading.

## Example template

Use this as a teleprompter / cue sheet. Left = Spoken (verbatim or bullets). Right = Visual / editing cues.

| Segment<br>& Time | Spoken (VERBATIM / prompts) | Visual / Action cues |
| :--- | :--- | :--- |
| Segment 1 — Hook & Promise (0:00–0:45) | VERBATIM: “You ask an AI a question — it answers instantly — but five minutes later it forgets you told it a patient detail. Smart, or pattern machine?”  <br><br> VERBATIM: “In under ten minutes you’ll know what actually happens when you send a message to an AI tool — and its built‑in limits.”  <br><br> Transition: “First: why language was harder than numbers.” | A‑roll face (hook)  <br><br> Slide 1 title: “Why AI ‘Forgets’”  <br><br> Lower‑third: Hook  <br><br> CUT → Slide 2 at transition |
| Segment 2 — Numbers vs Words (0:45–2:00) | Bullets (speak conversationally):  <br> • Classic ML = numbers (iris example)  <br> • Easy: fixed features, math comparisons  <br> • Text problem: naive word IDs create fake math (airplane − apple = aunt)  <br> • Needed: relationships, not IDs  <br><br> Transition: “That missing piece was attention.” | Slide 2: table of iris features (simple visual)  <br><br> Slide 3: word → ID diagram with big red X  <br><br> Slide 4: arrows between words (foreshadow attention) |
| Segment 3 — Attention (2:00–4:30) | VERBATIM definition: “Attention lets the model weight earlier words by relevance — not just the previous word.”  <br><br> Bullets:  <br> • Multiple heads = different relation types  <br> • Cost: scans prior tokens each new word  <br> • Probability over vocabulary → picks next token  <br> • Repeat loop  <br><br> Micro question: “So where does ‘memory’ live?” (pause) | Slide 5: sentence with colored lines showing attention links  <br><br> Overlay labels: ‘head 1’, ‘head 2’  <br><br> Slide 6: flow diagram: tokens → attention → probabilities  <br><br> CUT to head‑only briefly for the micro question |

## Quick usage notes
- Mark VERBATIM lines to memorize; convert unclear bullets into short verbatim lines before recording.  
- Keep each table row short; glance at Visual then speak Spoken column in 1–2 bullet chunks.  
- Use small pauses after transitions and questions.
